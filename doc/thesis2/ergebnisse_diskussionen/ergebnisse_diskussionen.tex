\chapter{Ergebnisse und Diskussion}



% /////////////////////////////////////////////////////////



\section{Überblick}
Abbildung \ref{lucy_s4_D13_timeseries} gibt einen allgemeinen Eindruck über die Laufzeiten der einzelnen Teilschritte, die in Abschnitt \ref{sec:echtzeitfaehiges_svo_raycasting} (\nameref{sec:echtzeitfaehiges_svo_raycasting}) beschrieben wurden und die Anzahl verarbeiteter Treelets. Die Werte wurden in Abständen von 200 ms abgegriffen.
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/lucy_s4_D13_timeseries.pdf}
  \caption{Systemzeiten und zu verarbeitende Treelets Treelets\label{lucy_s4_D13_timeseries}}
\end{figure}
Im oberen Graphen finden sich die Zeiten für das Erstellen des Analyse-Buffers, das Zurücklesen und dessen Vorsortierung in Sichtinformationen für neue und bereits geladene Treelets. Ausserdem sind die benötigten Zeiten für die Pflege des clientseitigen und serverseitigen Incore-Buffers dargestellt. Im unteren Graphen sind die Menge der von der Analyse des Baumes erzeugten Anfragen nach neuen Treelets, die Menge der daraufhin geänderten Slots und die Anzahl der benötigten Kopieraufrufe dargestellt.\\
Um Eigenschaften und Leistungsfähigkeit des Systems zu analysieren wurden im Zuge dieser Arbeit drei Tests durchgeführt. Der erste Test untersuchte den Einfluss der Treelet-Größe auf das Verhalten des Out-of-Core-Systems. Der zweite Test beschäftigt sich mit der Minimierung der Kopieraufrufe bei der serverseitigen Aktualisierung. Ein dritter Test soll die Reaktionsfähigkeit des Systems während der Benutzung untersuchen.\\
Als Testsystem stand ein aktuelles GNU/Linux-System mit Intel Core i7-2600 (3.4 GHz) und 32 GB Arbeitsspeicher zu Verfügung. Eine Nvidia GForce 580 GTX mit 1.5 GB Ram war über PCI-Express 2 angebunden. 


% /////////////////////////////////////////////////////////


\section{Verwendete Testmodelle}
 
Als Testdaten wurde drei Dreiecksmodelle mit Hilfe des in Kapitel \ref{sec:erzeugung_treelet_struktur} (\textit{\nameref{sec:erzeugung_treelet_struktur}}) beschrieben Systems in Sparse Voxel Octrees überführt. Aus jedem Modell wurden jeweils zwei SVO-Strukturen erstellt. Beide Varianten haben die selbe minimale Tiefe von 13 für alle Blattknoten, unterscheiden sich aber in der Treelet-Größe, die 1 kB und 4 kB beträgt. Tabelle \ref{tab:verwendete_modelle} zeigt die Anzahl der Dreiecke der verwendeten Ausgangsmodelle und Anzahl von Treelets und Voxel der resultierenden Octrees. 
Für alle Octrees wurden Attribut-Buffer mit Farb- und Normalenwerten erstellt die mit 16 Byte/Voxel aufgelöst sind die in den angegebenen zum Speicherbedarf bereits enthalten sind.\\
Das Modell "david face" stellt eine Besonderheit dar. Durch die feste Segmentgröße ist die Darstellung mit 4 kB-großen Treelets unverhältnismässig groß geworden.\\
Die SVO-Repräsentationen der Dreiecksmodelle sind in den Darstellungen mit 4 kB und 1 kB großen Treelets unterschiedlich groß. Dies ist auf die feste Segmentgröße zurückzuführen. Sie bleiben jedoch trotzdem Vergleichbar, da durch die Wirkungsweise des Systems nur Teile der Strukturen verarbeitet werden die für die Darstellung benötigt werden.


\begin{table}[position=h]
\changefont{ptm}{m}{n}
\normalsize
\centering
\begin{tabular}{ l  r  r  c  r r r}
\toprule
\textbf{Name} & \textbf{Dreiecke} & \textbf{Dateigröße} & \textbf{Treelet-Größe} & \textbf{Treelets} & \textbf{Voxel} & \textbf{Dateigröße} \\
\midrule
  david face        & 52.5 Mio & 14.7 GB & 1kb & 743.277 &  95.139.456 & 1.4 GB \\

                    &          &         & 4kb & 484.297 & 247.960.064 & 3.7 GB \\
\midrule
  Lucy              & 28.0 Mio & 757 MB & 1kb & 588.032  & 75.268.096 & 1.2 GB \\
                    &          &        & 4kb & 131.072  & 67.108.864 & 1.0 GB \\
\midrule
  xyzrgb statuette  & 10.0 Mio & 270 MB & 1kb & 781.302 & 100.006.656 & 1.5 GB \\
                    &          &        & 4kb & 246.434 & 126.174.208 & 1.9 GB \\ 
\bottomrule 
\end{tabular}\\
%\vspace{0.2cm}
%\hrule height 1pt width 1.0\hsize
\caption{Verwendete Modelle}\label{tab:verwendete_modelle}
\end{table}

% /////////////////////////////////////////////////////////////

\newpage

\section{Einfluss der Segmentgröße auf das Systemverhalten}\label{sec:test_einfluss_groesse}
\subsection{Versuchsaufbau}
Bei diesem Test soll der Einfluss der Speichergröße der Treelets auf das Laufverhalten des Systems untersucht werden. Dazu wurden für alle sechs Modelle die Werte wie sie in Abbildung \ref{lucy_s4_D13_timeseries} dargestellt sind aufgenommen. Aufnahme Zeit betrug in allen Durchläufen 30 Sekunden. In Intervallen von 200 ms wurde jeweils ein Wert notiert der dem Mittelwert aller in dieser Zeit erfolgten Programmzyklen entspricht.\\
Um das System zu belasten und die permanente die Veränderung des Incore-Buffers anzuregen wurden alle Modelle vor der Kamera platziert und mit $1/3$ Hz um die Hochachse rotiert. Mit der Bewegung sollte gewährleistet werden, dass das System in jedem Durchlauf eine hohe Anzahl von Anfragen nach neuen Treelets erzeugt und verarbeiten muss. Die Geschwindigkeit der Rotation wurde gewählt um einen wahrscheinlichen Anwendungs\-fall zu simulieren, in dem eine hohe Kohärenz zwischen den aufeinander\-folgenden Ansichten erwartet wird. Die Größe des Incore-Buffers wurde auf 256 MB festgelegt und entspricht damit $1/4$ bis $1/14$ der Speichergrößen der gesamten Octreedaten. Um das Laufverhalten über einen längeren Zeitraum zu simmulieren wurde das Model vor der eigentlichen Messung über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet. Dies führt zu einer unsystematischen Anordnung der Treelets im Incore-Buffer. Während der Messung wurde die Bildsynthese deaktiviert, um ausschließlich den Einfluss der Größe der Treelets auf den Ver\-walt\-ungsaufwand untersuchen zu können.



% /////////////////////////////////////////////////////////////



\subsection{Auswertung}
Die in Abbildung \ref{david_lucy_xyzrgb_s1_vs_24_D13} dargestellte Vergleich der Messergebnisse für unterschiedliche Treeletgrößen zeigt für alle drei Modelle ähnliche Tendenzen auf.\\
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/david_lucy_xyzrgb_s1_vs_24_D13.pdf}
  \caption{Gegenüberstellung unterschiedleichen Treelet-Größen\label{david_lucy_xyzrgb_s1_vs_24_D13}}
\end{figure}
\\
\subsubsection{Erstellung und Übertragung des Analyse-Buffers}
Zunächst kann festgestellt werden, dass die Erstellungszeit für den Analyse-Buffer für zwei der drei Beispiele in beiden Varianten annähernd konstant ist. Der Unterschied beim Modell \textit{david face} kann durch den enormen Unterschied in der Anzahl der Knoten beider Darstellungen erklärt werden der immerhin 260\% beträgt. Trotzdem benötigt die 4Kb Version nur ca. 0.2 ms mehr für das Erstellen des Buffers. Daraus läßt sich schließen dass die Größe der Treelets, für die Gewählten Werte von 1 kB und 4 kB, keinen nenenswerten Einfluss auf das beim Erstellen stattfindende Raycasting besitzt. Der Algorithmus skaliert sehr gut, trotz der Segmentierung.\\
Die nötige Übertragung des Analyse-Buffers in den Hauptspeicher der CPU läuft erwartungsgemäß in konstanter Zeit ab.

\subsubsection{Vorsortierung}
Der Vorsortierungsschritt benötigt bei allen drei Modellen für die Variante mit kleinen Treelets mehr Zeit als für ihre 4 kB Pendants. Der größere zu bewältigende Verwaltungsaufwand bei der Erstellung der Sichtinformation und Anfragen nach neuen Treelets dürfte der Grund für dieses Ergebniss sein. Beispielsweise muss bei der Behandlung eines Elementes des Analysebuffers das einen Knoten getroffen hatte, die Sichtbarkeit des Entsprechenden Treelets bis zu Wurzel-Treelet durchgereicht werden. Falls ein Treelet angehangen werden kann, wird der entsprechende Index mit dem Fehlerwert für diesen Bildpunkt in den Container mit allen Treelet-Anfragen sortiert um sie, ihrem Beitrag zur Bildqualität nach, einpflegen zu können.\\
Da die Unterteilung bei 1 kB großen Treelets feiner ist, ist auch der Weg zum Propagieren der Sichtbarkeitsinformationen länger. Auch ist der Vorgang bei kleinen Treelets wohl kaum Speicher\-kohärent da es wesentlich mehr Blätter und damit mehr Wege von Blättern zum Wurzel-Knoten gibt. Die feinere Unterteilung führt im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) zu einer Größeren Menge von Anfragen nach neuen Treelets.

\subsubsection{Clientseitige Aktualisierung}
Im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) sind die Zeiten für die Pflege des clientseitigen Incore-Buffers (obere Graphen, grün) nahezu identisch obwohl sich die Menge an vorhandenen Treelets der Modelle stark unterscheidet. Die großere Anzahl von Slot-Änderungen (untere Graphen, grau) weißt auf eine Mehrlast für mehr verwaltete Treelets hin. Besonders beim Modell \textit{lucy} mit 1 kB Treelets wird dies deutlich, da es mit Abstand die meisten Treelets der vier Octrees besitzt. Damit kann abgeleitet werden das die clientseitge Aktualisierung mit steigender Treelet-Anzahl gut skaliert. Allerdings lässt sich über alle Modelle eine stärkere Abhängigkeit der Laufzeit von den neu angeforderten Treelets (untere Graphen, lila) erkennen 

\subsubsection{Serverseitige Aktualisierung}
Das kopieren der geänderten Slot-Bereiche auf den Server beansprucht bei fast allen Versuchen einen großen Anteil der Laufzeit. Das Zusammenfassen der Slot-Bereiche funktioniert, wie ein Vergleich der Anzahl der geänderten Slots (unterer Graph, grau) mit der Anzahl der ausgeführten Kopieroperationen (unterer Graph, blau) veranschaulicht. Ob die Zusammenfassung tatsächlich einen Geschwindigkeitsvorteil gegenüber dem einzelnen Kopieren der Slot-Bereiche bring, sollte ein zweiter Test untersuchen der in Abschnitt \ref{sec:test_zusammenfassen_von_slots} (\textit{\nameref{sec:test_zusammenfassen_von_slots}}) dokumentiert ist.

\subsubsection{Anmerkungen zum Modell david face}
Das Modell \textit{david face} stellt eine Besonderheit unter den ausgewählten Testmodellen dar. Durch die Segmentierung mit 4 kB großen Treelets sind sehr viele Knoten entstanden, die unterhalb der geforderten Tiefe liegen. Dies passiert beim Aufbau der Octree-Struktur im Build-Manager, wenn die gewünschte Octree-Tiefe mit den bisher erstellten Treelets beinahe erreicht wurde. Auf Voxel-Ebene würde es genügen, noch einige wenige Unterteilungen vorzunehmen, um die benötigte Tiefe zu erreichen. Da aber für jeden Blattknoten des bisher erstellten Octrees neue Treelets von 4 kB Größe erzeugt werden, wird die Gesamtstruktur sehr groß. Anders ausgedrückt, will man einen Schnitt in der Tiefe 13 durch einen beliebig tiefen Octree abbilden, gelingt das mit 4 kB großen Segmenten für dieses Modell nur verhältnismäßig grob. Damit offenbart sich ein bedeutender Nachteil einer festen Segmentgröße. Die mögliche Anzahl von Knoten, deren Tiefe die geforderte minimale Baumtiefe übersteigt, erhöht sich mit jeder zusätzlichen Tiefenstufe, da die Anzahl der Blattknoten größer wird.\\
Vergleicht man die in den Graphen dargestellten Werte beider Modellvarianaten lassen sich weitere Rückschlüsse auf das Verhalten des Systems ziehen. Beispielsweise lässt sich feststellen, dass das System bei der Darstellung des Modells mit 1 kB großen Treelets kaum neue Treelets anforderte (unterer Graph, lila) und somit kaum Änderungen im clientseitigen Incore-Buffer erzeugte (unterer Graph, grau). Dagegen forderte die Modellvariante mit 4 kB großen Treelets fortwährend neue Treelets zur Anpassung an die aktuelle Ansicht an. Dies ist durch den Größenunterschied beider Modelle zu erklären. Die Modellvariante mit 1 kB großen Treelets ist mit 1.4 Gb wesentlich größer ist als der Incore-Buffer. Trotzdem gelingt es dem System einen Großteil der SVO-Struktur im Incore-Buffer zu halten, die für das Umfahren des Models auf einer Achse benötigt werden. Nur ein sehr kleiner Teil der Daten, die benötigt würden um alle Ansichten der bewegten Kamera fein aufzulösen, passt nicht mehr in den Incore-Buffer und wird ständig angefordert. Die resultierende Änderungen in der Belegung des Incore-Buffers scheint sich nur auf einen sehr kleinen, zusammenhängenden Bereich zu beschränken. Dafür spricht das gute Ergebnis bei der Zusammenfassung der zu kopierenden Slot-Bereiche (unterer Graph, grau) gegenüber dem Wert für die geänderten Slots und die Zeit für das Kopieren der Slots (oberer Graph, orange).\\
Noch deutlicher wird dies beim betrachten der Modelvariante mt 4 kb. Die Octree-Repräsentation mit 3.7 Gb übersteigt die Kapazität des Incore-Buffers um ein vielfaches. Hier muss der Octree ständig an die aktuelle Ansicht angepasst, da gerade nur die Teile im Incore-Buffer gehalten werden können die für die aktuelle Ansicht benötigt werden. Anhand der Menge angefragter Treelets, der Anzahl von geänderten Slotpositionen und der guten Zusammenfasbarkeit der geänderten Slot-Positionen läßt sich erkennen, dass immer große, zusammenhängende Teile des Incore-Buffers ausgetauscht werden.\\
Die theoretische Datenmenge die benötigt wird um beide Modellvarianten bis in die für die Ansichten benötigte Tiefe abzubilden ist für beide Varianten gleich. Dem System gelingt es jedoch wesentlich besser den tatsächlich benötigten Schnitt durch den Baum abzubilden, wenn kleinere Treelets verwendet werden. Der bessere Schnitt durch den Baum führt zu einer Verbesserung der Gesamtlaufzeit, was sich auch in den Messergebnissen der anderen Modelle feststellen lässt. Selbst beim Modell \textit{lucy} dessen Repräsentation mit 1. kB großen Treelets deutlich mehr Knoten besitzt als die Variante mit 4 kB großen Treelets kann eine bessere Gesamtleistung festgestellt werden. Mit der größeren Anzahl von Treelets steigt jedoch in allen drei Beispielen der Verwaltungsaufwand bei der Vorsortierung (oberer Graph, gelb). Wird die Größe der Treelets zu klein ist vorstellbar, dass der Verwaltungsaufwand für die vielen Treelets den Geschwindigkeitsvorteil durch einen besser abbildbaren Schnitt im Baum, zunichte macht. Die optimale Treeletgröße für dieses System mit gegeben Modell, sollte in weiteren Test untersucht werden.


% /////////////////////////////////////////////////////////////


\section{Zusammenfassen von Slots bei der Serverseitige Aktualisierung}\label{sec:test_zusammenfassen_von_slots}

Einen großer Teil der Laufzeit des Out-of-Core-Systems wird vom Aktualisieren des serverseitigen Incore-Buffers beansprucht. Daher hätte eine Optimierung dieses Vorgangs einen großen Einfluss auf die Gesamtleistung des Systems. Es wurde zunächst vermutet das die große Anzahl der Kopieropterationen vom clientseitigen zum serverseitigen Incore-Buffer für den Großteil der benötigten Zeit verantwortlich ist. Mit dem Zusammenfassen der Speicherbereiche mehrerer zu aktualisierenden Slots wurde versucht die Anzahl der Kopieroperationen zu minimieren. Der eingestellte Anteil der Nutzdaten an dem zu kopierenden Speicherbereich wirkt sich dabei entscheident auf die benötigte Laufzeit ab. Ist der Anteil zu hoch festgelegt können nur wenige Bereiche zusammengefasst werden. Ist er dagegen zu hoch wird im Extremfall der Bereich des gesamten Incore-Buffer zu einer Kopieroperation zusammengefasst. Das wäre sehr ungünstig da zum Übertragen einer so großen Datenmenge mehr Zeit benötigt würde als bei der Einzel\-übertragung der Slot-Bereiche. Es muss also eine Einstellung für den Anteil von Nutzdaten geben der die benötigte Zeit für das Kopieren minimiert. Um diese Einstellung für eine gegebene Konfiguration von Incore-Buffer-Größe und Eingabedaten zu finden wurde dieser Test durchgeführt.


\subsection{Versuchsaufbau}
Das Modell \textit{david face} mit 4 kB großen Treelets wurde analog zum ersten Test vor der Kamera bewegt. In zehn Durchläufen wurden die Zeit für die serverseitige Aktualisierung, die Menge der veränderten Slots und die Anzahl der ausgeführten Kopieroperationen über 30 Sekunden aufgezeichnet. Dabei wurde der geforderte Nutzdatenanteil in jedem Durchlauf von $0$ beginnend, um 0.1 erhöht. Um Artefakte in den gemessenen Werten zu verhindern, wurde das Model wieder vor der eigentlichen Messung über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet.


\subsection{Auswertung}
Abbildung \ref{ratio_0_1} zeigt die Ergebnisse für die gemessene Zeit für das Kopieren, die Anzahl von geänderten Slots und die für die durchgeführten Kopieroperationen. Dabei entspricht ein Anteil von 0 dass kopierte Bereiche keine Nutzdaten enthalten müssen. Ein Anteil von 1.0 verlangt dagegen dass jeder in einem zu kopierten Bereich liegender Slot auch kopiert werden muss. In der Abbildung lässt sich ein Optimum für den Nutzdatenanteiles bei 0.6 erkennen. Mit dieser Einstellung betrug die Zeit für die Übertragung im Durchschnitt bei 2.48 ms. Zum Vergleich lag die Zeit für das einzelne Kopieren der Bereiche im Durchschnitt bei bei 4.23 ms. Der im Graph nicht dargestellte Wert für einen Nutzdatenanteil von Null lag dagegen bei 52.51 ms.\\
Ein Optimum existiert also und kann in der Anwendung auch ausgenutzt werden. Wie sich der Wert jedoch im laufenden System ändert und wie er in Abhängigkeit zu anderen Systemparametern steht konnte im Zuge dieser Arbeit nicht untersucht werden.


\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/ratio_0-1.pdf}
  \caption{Idealwert für Nutzdatenanteil\label{ratio_0_1}}
\end{figure}


% /////////////////////////////////////////////////////////////


\section{Test der Reaktionsfähigkeit des Systems}
In diesem Versuch sollte die Reaktionsfähigkeit des Systems untersucht werden. Dazu wurde die Zeit gemessen die das System benötigt um auf eine Sichtveränderung zu reagieren in dem es den aktuell sichtbaren Teil des Octrees bis zum nötigen beziehungsweise möglichen Grad verfeinert. Die Anzahl der zur Verfeinerung angeforderten Treelets kann dabei als Fehlerwert, für den momentan im Incore-Buffer befindlichen Teil des Octrees gegenüber einer Ansicht auf den gesamten Octree, gesehen werden.


\subsection{Versuchsaufbau}
Für diesen Test wurde die betrachtende Kamera zunächst auf das SVO-Model gerichtet und dann die Verfeinerung des Octrees aktiviert. Nachdem die Verfeinerung für diese Ansicht abgeschlossen war wurde die Kamera in einer schnellen Bewegung auf das Modell zu bewegt um davor wieder zum Stehen zu kommen. Wieder wurde gewartet bis die Verfeinerung der Ansicht abgeschlossen war. Danach wurde das Modell noch einmal in einer schnellen Bewegung umkreist. Wärent dieses Ablaufs wurden Werte für die Kamerageschwindigkeit, die benötigte Zeit für die Bildsynthese und den Gesamtzyklus sowie für die Anzahl der angeforderten Treelets aufgezeichnet.


\subsection{Auswertung}
Die in Abschnitt \ref{sec:streaming_vorsortierung} \textit{\nameref{sec:streaming_vorsortierung}} besprochene Vorsortierung der Treelet-Anfragen spielt für die Bewertung der Ergebnisse dieses Versuches eine wichtige Rolle. Die Sortierung der Anfragen nach ihrem Fehler in der Darstellung sorgt dafür, dass zuerst die Treelets eingepflegt werden die den größten Beitrag zur Darstellungs\-qualität liefern. Somit finden Verfeinerungen von groben Strukturen zuerst statt während im weiteren Verlauf der Verfeinerung einer Ansicht die Darstellungs\-qualität kaum noch steigt. Das in Abschnitt \ref{sec:streaming_analyse_pass} (\textit{\nameref{sec:streaming_analyse_pass}}) beschriebene Verfahren führt dazu, dass die Verfeinerung nie wirklich beendet ist, da bedingt durch die Unterabtastung beim Füllen des Analyse-Buffers immer wieder Blattknoten getroffen werden die in keinem Vorherigen Analyse-Pass zu sehen waren. Dazu müssen diese aber sehr klein sein um längere Zeit vom Analyse-Pass unentdeckt geblieben zu sein. Daher ist auch deren Beitrag zur Bild\-qualität zu vernachlässigen. Abbildung \ref{progressive_refinement} zeigt die Verfeinerung einer Ansicht in fünf auf einander folgenden Schritten. Der Fehler in der Darstellung ist in der unteren Reihe auf einen Farbverlauf von Grün über Gelb nach Rot abgebildet. Die Darstellungen lassen erkennen, dass die Verfeinerung bereits nach wenigen Schritten so weit vorangeschritten ist, dass die weiterhin stattfindende Verfeinerung kaum noch zur wahrgenommenen Bildqualität beiträgt.

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/progressive_refinement.png}
  \caption{Verfeinerung für eine Ansicht in fünf Schritten\label{progressive_refinement}}
\end{figure}

\newpage
Abbildung \ref{kamera_fahrt} zeigt die Ergebnisse der durchgeführten Messung und die aufgenommenen Werte im zeitlichen Verlauf. Von Zeitpunkt Null an beginnt die Verfeinerung der Octree-Struktur und ist nach etwa 3.5 Sekunden praktisch abgeschlossen. Nach vier Sekunden beginnt die Kamera\-bewegung in Richtung Modell, welche nach weiteren fünf Sekunden beendet ist. In dieser Zeit ist ein deutlicher Anstieg der benötigten Zeit für die Bildsynthese zu beobachten, da bedingt durch die steigende Fläche des abgebildeten Models im Bildausschnitt beim Raycasting mehr Strahlen den Octree traversieren müssen. Ab etwas der Hälfte der Zeit beginnt die Verfeinerung des weiter voranzuschreiten da Octree-Tiefe der geladenen Treelets nicht mehr für die Darstellung in dieser Entfernung genügt. Vier Sekunden nach der Beendigung der Kamerabewegung ist die Menge der angefordeten Treelets wieder auf ein sehr geringen Wert gefallen. Abbildung \ref{difference} zeigt das Bild während des Testdurchlaufs zum Zeitpunkt 8.5 Sekunden und 12.5 Sekunden. Im daneben abgebildeten Differenzbild ist deutlich zu erkennen wie wenig die in diesen vier Sekunden eingepflegten Treelets noch zur Darstellungs\-qualität beitragen. Es handlet sich meist um pixelgroße Stellen. Die Anordnung der im Differnzbild zeigt deutliche Aliasingartefakte was auf die Arbeitsweise des Analyse-Passes zurückgeführt werden kann. 

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/difference.png}
  \caption{Unterschiede der Verfeinerung zu zwei Zeitpunken\label{difference}}
\end{figure}

In der 13 Sekunde des Tests beginnt die umkreisende Bewegung der Kamera, die zu einem deutlichen Anstieg der Menge der angeforderten Treelets führt. Bei 18.5 Sekunden ist die Umkreisung so weit vorangeschritten das wieder Bereiche des Modells dargestellt werden die im bisherigen verlaufes des Test schon gesehen wurden. Damit singt auch die Menge der angeforderten Treelets. Bei 22.5 Sekunden beginnt die Menge der angeforderten Treelets nocheinmal zu steigen. Offenbar waren die für die Frontansicht des Models benötigtwn Treelets bereits aus dem Incore-Buffer verdrängt worden.\\
Drei Sekunden nach Beendigung der Umkreisung hatte sich die im Incore-Buffer enthalte Octree-Struktur wieder der Ansicht angepasst.\\
\\
Der Test zeigt, dass das vorgestellten Out-of-Core-System schnell auf Veränderungen der Ansicht mit Änderungen der Auswahl der Octree-Segmente reagieren kann.    

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/kamera_fahrt.pdf}
  \caption{Reaktionszeit des Systems\label{kamera_fahrt}}
\end{figure}

% /////////////////////////////////////////////////////////////

\newpage
\newpage
\section{Einschränkungen und Verbesserungen}

\subsection{Verwendung von OpenGL Texturen als Buffer}
\subsection{Entkoppelung des Out-of-Core-Systems von der Bilderzeugung}
...
