\chapter{Ergebnisse und Diskussion}\label{se:ergebnisse_diskusionen}



% /////////////////////////////////////////////////////////



\section{Überblick}
Abbildung \ref{lucy_s4_D13_timeseries} gibt einen allgemeinen Eindruck über die Laufzeiten der einzelnen Teilschritte, die in Abschnitt \ref{sec:echtzeitfaehiges_svo_raycasting} \textit{\nameref{sec:echtzeitfaehiges_svo_raycasting}} beschrieben wurden sowie über die Anzahl verarbeiteter Treelets. Die Werte wurden in Abständen von 200 ms aufgezeichnet.
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/lucy_s4_D13_timeseries.pdf}
  \caption{Systemzeiten und zu verarbeitende Treelets\label{lucy_s4_D13_timeseries}}
\end{figure}
Im oberen Teil der Abbildung finden sich die Zeiten für das Befüllen und die Übertragung des Analyse-Buffers sowie die Vorsortierung in Sichtinformationen für neue und bereits geladene Treelets. Ausserdem sind die benötigten Zeiten für die Pflege des clientseitigen und serverseitigen Incore-Buffers dargestellt. Im unteren Graphen sind die Menge der von der Analyse des Baumes erzeugten Anfragen nach neuen Treelets, die Anzahl der daraufhin geänderten Slots und die Anzahl der benötigten Kopieraufrufe dargestellt.\\
Um die Eigenschaften und Leistungsfähigkeit des Systems zu analysieren wurden im Zuge dieser Arbeit drei Tests durchgeführt. Der erste Test untersucht den Einfluss der Treelet-Größe auf das Verhalten des Out-of-Core-Systems. Der zweite Test untersucht das Verfahren zur Minimierung der Kopieraufrufe bei der serverseitigen Aktualisierung (vgl. Abschnitt \ref{sec:serverseitige_aktualisierung} \textit{\nameref{sec:serverseitige_aktualisierung}} ). Ein dritter Test soll die Reaktionsfähigkeit des Systems während der Benutzung untersuchen.\\
Als Testsystem stand ein aktuelles GNU/Linux-System mit Intel Core i7-2600 (3.4 GHz) und 32 GB Arbeitsspeicher zu Verfügung. Eine Nvidia GForce 580 GTX mit 1.5 GB Ram war über PCI-Express 2 angebunden. 


% /////////////////////////////////////////////////////////


\section{Verwendete Testmodelle}
 
Als Testdaten wurden drei Dreiecksmodelle mit Hilfe des in Kapitel \ref{sec:erzeugung_treelet_struktur} (\textit{\nameref{sec:erzeugung_treelet_struktur}}) beschrieben Systems in Sparse Voxel Octrees überführt. Aus jedem Modell wurden jeweils zwei SVO-Strukturen erstellt. Beide Varianten haben die gleiche minimale Tiefe von 13 für alle Blattknoten, unterscheiden sich aber in der Treelet-Größe. Diese beträgt jeweils 1 kB und 4 kB. Tabelle \ref{tab:verwendete_modelle} zeigt die Anzahl der Dreiecke der verwendeten Ausgangsmodelle und Anzahl von Treelets und Voxel der resultierenden Octrees. 
Für alle Octrees wurden Attribut-Buffer mit Farb- und Normalenwerten erstellt die mit 16 Byte/Voxel aufgelöst sind.\\
Das Modell "david face" stellt eine Besonderheit dar. Durch die feste Segmentgröße ist die Darstellung mit 4 kB-großen Treelets unverhältnismässig groß geworden.\\
Die SVO-Repräsentationen der Dreiecksmodelle sind in den Darstellungen mit 4 kB und 1 kB großen Treelets unterschiedlich groß. Dies ist auf die feste Segmentgröße zurückzuführen. Sie bleiben jedoch trotzdem vergleichbar, da durch die Wirkungsweise des Systems nur Teile der Strukturen verarbeitet werden die für die Darstellung benötigt werden.


\begin{table}[position=h]
\changefont{ptm}{m}{n}
\normalsize
\centering
\begin{tabular}{ l  r  r  c  r r r}
\toprule
\textbf{Name} & \textbf{Dreiecke} & \textbf{Dateigröße} & \textbf{Treelet-Größe} & \textbf{Treelets} & \textbf{Voxel} & \textbf{Dateigröße} \\
\midrule
  david face        & 52.5 Mio & 1.47 GB & 1kb & 743.277 &  95.139.456 & 1.4 GB \\

                    &          &         & 4kb & 484.297 & 247.960.064 & 3.7 GB \\
\midrule
  Lucy              & 28.0 Mio & 757 MB & 1kb & 588.032  & 75.268.096 & 1.2 GB \\
                    &          &        & 4kb & 131.072  & 67.108.864 & 1.0 GB \\
\midrule
  xyzrgb statuette  & 10.0 Mio & 270 MB & 1kb & 781.302 & 100.006.656 & 1.5 GB \\
                    &          &        & 4kb & 246.434 & 126.174.208 & 1.9 GB \\ 
\bottomrule 
\end{tabular}\\
%\vspace{0.2cm}
%\hrule height 1pt width 1.0\hsize
\caption{Verwendete Modelle}\label{tab:verwendete_modelle}
\end{table}

% /////////////////////////////////////////////////////////////

\newpage

\section{Einfluss der Segmentgröße auf das Systemverhalten}\label{sec:test_einfluss_groesse}
\subsection{Versuchsaufbau}
Bei diesem Test soll der Einfluss der Speichergröße der Treelets auf das Laufverhalten des Systems untersucht werden. Dazu wurden für alle sechs Octrees die Werte, wie sie in Abbildung \ref{lucy_s4_D13_timeseries} dargestellt sind aufgenommen. Aufnahme Zeit betrug in allen Durchläufen 30 Sekunden. In Intervallen von 200 ms wurde jeweils der Mittelwert aller in dieser Zeit erfolgten Programmzyklen notiert.\\
Um das System zu belasten und eine anhaltende Veränderung des Incore-Buffers anzuregen, wurden alle Modelle vor der Kamera mit $1/3$ Hz um die Hochachse rotiert. Mit der Bewegung sollte gewährleistet werden, dass das System in jedem Durchlauf eine hohe Anzahl von Anfragen nach neuen Treelets erzeugt und verarbeiten muss. Die Geschwindigkeit der Rotation wurde gewählt um einen wahrscheinlichen Anwendungs\-fall zu simulieren, in dem eine hohe Kohärenz zwischen den aufeinander\-folgenden Ansichten erwartet wird. Die Größe des Incore-Buffers wurde auf 256 MB festgelegt und entspricht damit $1/14$ bis $1/4$ der Speichergrößen der gesamten Octreedaten. Um das Laufverhalten über einen längeren Zeitraum zu simmulieren wurde das Model vor der eigentlichen Messung über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet. Dies führt zu einer unsystematischen Anordnung der Treelets im Incore-Buffer. Während der Messung wurde die Bildsynthese deaktiviert, um ausschließlich den Einfluss der Größe der Treelets auf den Ver\-walt\-ungsaufwand untersuchen zu können.



% /////////////////////////////////////////////////////////////



\subsection{Auswertung}
Die in Abbildung \ref{david_lucy_xyzrgb_s1_vs_24_D13} dargestellte Vergleich der Messergebnisse für unterschiedliche Treeletgrößen zeigt für alle drei Modelle ähnliche Tendenzen auf.\\
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/david_lucy_xyzrgb_s1_vs_24_D13.pdf}
  \caption{Gegenüberstellung von unterschiedlichen Treelet-Größen\label{david_lucy_xyzrgb_s1_vs_24_D13}}
\end{figure}
\\
\subsubsection{Erstellung und Übertragung des Analyse-Buffers}
Zunächst kann festgestellt werden, dass die Erstellungszeit für den Analyse-Buffer für zwei der drei Beispiele in beiden Varianten annähernd konstant ist. Der Unterschied beim Modell \textit{david face} kann durch den enormen Unterschied in der Anzahl der Knoten beider Darstellungen erklärt werden. Der größere Octree enthält die 2.6-fache Menge an Knoten im Vergleich zum kleineren Octree. Trotzdem benötigt die 4 Kb Version nur ca. 0.2 ms mehr für das Erstellen des Buffers. Daraus läßt sich schließen, dass die Größe der Treelets für die gewählten Werte von 1 kB und 4 kB keinen nenenswerten Einfluss auf das beim Erstellen stattfindende Raycasting besitzt. Der Algorithmus skaliert sehr gut, trotz der Segmentierung.\\
Die nötige Übertragung des Analyse-Buffers in den Hauptspeicher der CPU läuft erwartungsgemäß in konstanter Zeit ab.

\subsubsection{Vorsortierung}
Der Vorsortierungsschritt benötigt bei allen drei Modellen für die Variante mit kleinen Treelets mehr Zeit als für die Darstellungen mit 4 kB großen Treelets. Der größere Verwaltungsaufwand bei der Erstellung der Sichtinformation und Anfragen nach neuen Treelets dürfte der Grund für dieses Ergebniss sein. Beispielsweise muss bei der Behandlung eines Elementes des Analysebuffers das einen Knoten getroffen hatte, die Sichtbarkeit des entsprechenden Treelets bis zum Wurzel-Treelet propagiert werden. Falls ein Treelet angehangen werden kann, wird der entsprechende Index mit dem Fehlerwert für diesen Bildpunkt in den Container mit allen Treelet-Anfragen sortiert um sie, ihrem Beitrag zur Bildqualität nach, einpflegen zu können.\\
Da die Unterteilung bei 1 kB großen Treelets feiner ist, ist auch der Weg zum Propagieren der Sichtbarkeitsinformationen länger. Auch ist der Vorgang bei kleinen Treelets wenig Speicher\-kohärent, da es wesentlich mehr Blätter und damit mehr Wege von den Blättern zum Wurzel-Knoten gibt. Die feinere Unterteilung führt im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) zu einer größeren Menge von Anfragen nach neuen Treelets.

\subsubsection{Clientseitige Aktualisierung}
Im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) sind die Zeiten für die Aktualisierung des clientseitigen Incore-Buffers (obere Graphen, grün) nahezu identisch obwohl die Anzahl der vorhandenen Treelets sich zwischen den der Modellen stark unterscheidet. Die größere Anzahl von Slot-Änderungen (untere Graphen, grau) weist auf eine Mehrlast für zur Verwaltung der Treelets hin. Besonders beim Modell \textit{lucy} mit 1 kB Treelets wird dies sichtbar, da es deutlich mehr Treelets enthält als die anderen drei Octrees. Daraus kann abgeleitet werden, dass die clientseitge Aktualisierung mit steigender Treelet-Anzahl gut skaliert. Allerdings lässt sich über alle Modelle eine stärkere Abhängigkeit der Laufzeit von der Anzahl der neu angeforderten Treelets (untere Graphen, lila) erkennen.

\subsubsection{Serverseitige Aktualisierung}
Das Kopieren der geänderten Slot-Bereiche auf den Server beansprucht bei fast allen Versuchen einen großen Anteil der Laufzeit. Das Zusammenfassen der Slot-Bereiche funktioniert, wie ein Vergleich der Anzahl der geänderten Slots (unterer Graph, grau) mit der Anzahl der ausgeführten Kopieroperationen (unterer Graph, blau) veranschaulicht. Ob die Zusammenfassung tatsächlich einen Geschwindigkeitsvorteil gegenüber dem einzelnen Kopieren der Slot-Bereiche bring, wurde in einem weiteren Test untersucht, der in Abschnitt \ref{sec:test_zusammenfassen_von_slots} (\textit{\nameref{sec:test_zusammenfassen_von_slots}}) dokumentiert ist.

\subsubsection{Anmerkungen zum Modell david face}
Das Modell \textit{david face} stellt eine Besonderheit unter den ausgewählten Testmodellen dar. Durch die Segmentierung mit 4 kB großen Treelets sind sehr viele Knoten entstanden, die unterhalb der geforderten Tiefe liegen. Dies passiert beim Aufbau der Octree-Struktur im Build-Manager, wenn die gewünschte Octree-Tiefe mit den bisher erstellten Treelets beinahe erreicht wurde. Auf Voxel-Ebene würde es genügen, noch einige wenige Unterteilungen vorzunehmen, um die benötigte Tiefe zu erreichen. Da aber für jeden Blattknoten des bisher erstellten Octrees neue Treelets von 4 kB Größe erzeugt werden, wird die Gesamtstruktur sehr groß. Anders ausgedrückt, will man einen Schnitt in der Tiefe 13 durch einen beliebig tiefen Octree abbilden, gelingt das mit 4 kB großen Segmenten für dieses Modell nur verhältnismäßig grob. Damit offenbart sich ein bedeutender Nachteil einer festen Segmentgröße. Die mögliche Anzahl von Knoten, deren Tiefe die geforderte minimale Baumtiefe übersteigt, erhöht sich mit jeder zusätzlichen Tiefenstufe, da die Anzahl der Blattknoten größer wird.\\
Vergleicht man die in den Graphen dargestellten Werte beider Modellvarianaten lassen sich weitere Rückschlüsse auf das Verhalten des Systems ziehen. Beispielsweise lässt sich feststellen, dass das System bei der Darstellung des Modells mit 1 kB großen Treelets kaum neue Treelets anforderte (unterer Graph, lila) und somit kaum Änderungen im clientseitigen Incore-Buffer erzeugte (unterer Graph, grau). Dagegen forderte die Modellvariante mit 4 kB großen Treelets fortwährend neue Treelets zur Anpassung an die aktuelle Ansicht an. Dies ist durch den Größenunterschied beider Modelle zu erklären. Die Modellvariante mit 1 kB großen Treelets ist mit 1.4 Gb wesentlich größer ist als der Incore-Buffer. Trotzdem gelingt es dem System einen Großteil der SVO-Struktur im Incore-Buffer zu halten, der für das Umfahren des Models auf einer Achse benötigt wird. Nur ein sehr kleiner Teil der Daten, die benötigt würden um alle Ansichten der bewegten Kamera optimal aufzulösen, passt nicht mehr in den Incore-Buffer und wird ständig angefordert. Die resultierenden Änderungen in der Belegung des Incore-Buffers scheint sich nur auf einen sehr kleinen, zusammenhängenden Bereich zu beschränken. Dies kann anhand des Verhältnisses der Anzahl an geänderten Slot-Bereichen(unterer Graph, grau) und der Anzahl der durchgeführten Kopieroperationen( unterer Graph, blau) und anhand der für das Kopieren der Slots benötigten Zeit (oberer Graph, orange) erkannt werden.\\
Noch deutlicher wird dies beim Betrachten der Modelvariante mt 4 kB großen Treelets. Die Octree-Repräsentation mit 3.7 Gb übersteigt die Kapazität des Incore-Buffers um ein Vielfaches. Hier muss der Octree ständig an die aktuelle Ansicht angepasst werden, da zu jedem Zeitpunkt nur die Teile im Incore-Buffer gehalten werden können, die für die aktuelle Ansicht benötigt werden. Anhand der Menge angefragter Treelets, der Anzahl von geänderten Slotpositionen und der wenigen Kopieroperationen lässt sich erkennen, dass immer große, zusammenhängende Teile des Incore-Buffers ausgetauscht werden.\\
Die Datenmenge die theoretisch benötigt wird, um beide Modellvarianten bis in die für die Ansichten benötigte Tiefe abzubilden ist für beide Varianten gleich. Der tatsächlich benötigte Schnitt durch den Octree kann vom System jedoch genauer mit kleinen Treelets angebildet werden. Der präzisiere Schnitt durch den Baum führt wiederum zu einer Verbesserung der Gesamtlaufzeit. Dies lässt sich auch in den Messergebnissen der anderen Modelle feststellen. Selbst beim Modell \textit{lucy}, dessen Repräsentation mit 1 kB großen Treelets deutlich mehr Knoten besitzt, als die Variante mit 4 kB großen Treelets, kann eine bessere Gesamtleistung festgestellt werden. Mit der größeren Anzahl von Treelets steigt jedoch in allen drei Beispielen der Verwaltungsaufwand bei der Vorsortierung (oberer Graph, gelb). Wird die Größe der Treelets zu klein, kann der Verwaltungsaufwand für die vielen Treelets den Geschwindigkeitsvorteil durch einen besser abbildbaren Schnitt im Baum zunichte machen. Die optimale Treeletgröße in Abhängigkeit vom verwendeten Modell, sollte in weiteren Tests untersucht werden.


% /////////////////////////////////////////////////////////////


\section{Zusammenfassen von Slots bei der serverseitigen Aktualisierung}\label{sec:test_zusammenfassen_von_slots}

Ein großer Teil der Laufzeit des Out-of-Core-Systems wird vom Aktualisieren des serverseitigen Incore-Buffers beansprucht. Daher hätte eine Optimierung dieses Vorgangs einen großen Einfluss auf die Gesamtleistung des Systems. Es wurde zunächst vermutet, dass die große Anzahl der Kopier\-operationen vom clientseitigen zum serverseitigen Incore-Buffer für den Großteil der benötigten Zeit verantwortlich ist. Mit dem Zusammenfassen der Speicherbereiche mehrerer Slots wurde versucht, die Anzahl der Kopieroperationen zu minimieren. Der festgelegte Anteil der Nutzdaten an dem zu kopierenden Speicherbereich wirkt sich dabei entscheidend auf die benötigte Laufzeit aus. Ist der Anteil zu hoch, können nur wenige Bereiche zusammengefasst werden. Ist er dagegen zu niedrig, wird im Extremfall der Bereich des gesamten Incore-Buffer zu einer Kopieroperation zusammengefasst. Zum Übertragen einer so großen Datenmenge würde mehr Zeit benötigt werden, als bei der Einzel\-übertragung der Slot-Bereiche. Es muss also einen Wert für den Anteil von Nutzdaten geben, bei dem die benötigte Zeit für das Kopieren minimiert wird. Dieser Test wurde durchgeführt um diesen Wert für eine gegebene Konfiguration von Incore-Buffer-Größe und Eingabedaten zu finden.


\subsection{Versuchsaufbau}
Das Modell \textit{david face} mit 4 kB großen Treelets wurde analog zum ersten Test vor der Kamera bewegt. In zehn Durchläufen wurden zeitliche Aufwand für die serverseitige Aktualisierung, die Menge der veränderten Slots und die Anzahl der ausgeführten Kopieroperationen über 30 Sekunden aufgezeichnet. Dabei wurde der geforderte Nutzdatenanteil in jedem Durchlauf mit 0 beginnend, um 0.1 bis zu einem wert von 1 erhöht. Um Artefakte in den gemessenen Werten zu verhindern, wurde das Model wie im vorherigen Test über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet, bevor mit den Messungen begonnen wurde.


\subsection{Auswertung}
Abbildung \ref{ratio_0_1} stellt die gemessene Zeit für das Kopieren, die Anzahl von geänderten Slots und die für die durchgeführten Kopieroperationen dar. Dabei besgt ein Anteil von 0, dass kopierte Bereiche keine Nutzdaten enthalten müssen. Ein Anteil von 1 bedeutet dagegen, dass jeder in einem zu kopierenden Bereich liegender Slot auch geänderte Daten enhalten muss. In der Abbildung lässt sich ein Optimum für einen Nutzdatenanteil von 0.6 erkennen. Mit dieser Einstellung betrug die Zeit für die Übertragung im Durchschnitt 2.48 ms. Zum Vergleich lag die Zeit für das separate Kopieren einzelner Slots im Durchschnitt bei 4.23 ms. Der im Graph nicht sichtbare Wert für einen Nutzdatenanteil von 0 lag bei 52.51 ms.\\
Ein Optimum scheint also zu existieren. Wie sich der Wert jedoch im laufenden System ändert und wie er von anderen Systemparametern abhängt, wurde im Zuge dieser Arbeit nicht untersucht.


\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/ratio_0-1.pdf}
  \caption{Idealwert für Nutzdatenanteil\label{ratio_0_1}}
\end{figure}


% /////////////////////////////////////////////////////////////


\section{Test der Reaktionsfähigkeit des Systems}

In diesem Versuch soll die Reaktionsfähigkeit des Systems untersucht. Dazu wurde die Zeit gemessen, die das System benötigt um auf eine Sichtveränderung zu reagieren, indem es den aktuell sichtbaren Teil des Octrees bis zum nötigen beziehungsweise möglichen Grad verfeinert. Die Anzahl der zur Verfeinerung angeforderten Treelets kann dabei als Fehlerwert, für den momentan im Incore-Buffer befindlichen Teil des Octrees im Vergleich zu einem für diese Ansicht optimalen Octree, gesehen werden.


\subsection{Versuchsaufbau}

Für diesen Test wurde die Kamera zunächst auf das Modell gerichtet und dann die Verfeinerung des Octrees aktiviert. Nachdem die Verfeinerung für diese Ansicht abgeschlossen war, wurde die Kamera schnell auf das Modell zu bewegt, um davor wieder zum Stehen zu kommen. Nachdem die Verfeinerung des Octrees für diese Ansicht abgeschlossen war, wurde das Modell noch einmal in einer schnellen Bewegung umkreist. Während dieses Ablaufs wurden Werte für die Kamerageschwindigkeit, die benötigte Zeit für die Bildsynthese und den Gesamtzyklus sowie für die Anzahl der angeforderten Treelets aufgezeichnet. Der Bewegungsablauf soll das Verhalten eines Betrachters simulieren.


\subsection{Auswertung}
Die in Abschnitt \ref{sec:streaming_vorsortierung} \textit{\nameref{sec:streaming_vorsortierung}} besprochene Anordnung der Treelet-Anfragen spielt für die Bewertung der Ergebnisse dieses Versuches eine wichtige Rolle. Die Sortierung der Anfragen nach ihrem Fehler in der Darstellung sorgt dafür, dass zuerst diejenigen Treelets eingepflegt werden, die den größten Beitrag zur Darstellungs\-qualität liefern. Somit finden Verfeinerungen von groben Strukturen zuerst statt, während im späteren Verlauf der Verfeinerung einer Ansicht die Darstellungs\-qualität nur noch unbedeutend steigt. Das in Abschnitt \ref{sec:streaming_analyse_pass} (\textit{\nameref{sec:streaming_analyse_pass}}) beschriebene Verfahren führt dazu, dass die Verfeinerung nie abgeschlossen ist, da bedingt durch die Unterabtastung beim Füllen des Analyse-Buffers immer wieder Blattknoten getroffen werden, die in keinem vorherigen Analyse-Pass sichtbar waren. Knoten, die von Analyse-Pass lange unentdeckt bleiben, sind meist klein. Daher ist auch ihr Beitrag zur Bild\-qualität vernachlässigbar klein. Abbildung \ref{progressive_refinement} zeigt die Verfeinerung einer Ansicht in fünf aufeinanderfolgenden Schritten. Der Darstellung\-fehler ist in der unteren Reihe auf einen Farbverlauf von Grün über Gelb nach Rot abgebildet. Die Abbildungen lassen erkennen, dass die Verfeinerung bereits nach wenigen Schritten so weit vorangeschritten ist, dass die weiterhin stattfindende Verfeinerung kaum noch zur wahrgenommenen Bildqualität beiträgt.

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/progressive_refinement.png}
  \caption{Verfeinerung für eine Ansicht in fünf Schritten\label{progressive_refinement}}
\end{figure}

\newpage
Abbildung \ref{kamera_fahrt} zeigt die Ergebnisse der durchgeführten Messung und die aufgenommenen Werte im zeitlichen Verlauf. Von Zeitpunkt Null an beginnt die Verfeinerung der Octree-Struktur und ist nach etwa 3.5 Sekunden praktisch abgeschlossen. Nach vier Sekunden beginnt die Kamera\-bewegung in Richtung Modell, welche nach weiteren fünf Sekunden beendet ist. In dieser Zeit steigt die für die Bildsynthese benötigte Zeit deutlich an. Dies ist dadurch bedingt, dass durch die wachsende Fläche des abgebildeten Models im Bildausschnitt beim Raycasting mehr Strahlen den Octree traversieren müssen. Bei 6 Sekunden beginnt die Verfeinerung weiter voranzuschreiten, da die Tiefe der geladenen Treelets nicht mehr für die Darstellung des Modells in dieser Entfernung ausreicht. Vier Sekunden nach der Beendigung der Kamerabewegung ist die Menge der angefordeten Treelets wieder auf einen sehr geringen Wert gefallen. Abbildung \ref{difference} zeigt das Bild während des Testdurchlaufs zum Zeitpunkt 8.5 Sekunden (links) und 12.5 Sekunden (mitte). Im Differenzbild (rechts) ist deutlich zu erkennen wie wenig die in diesen vier Sekunden eingepflegten Treelets noch zur Darstellungs\-qualität beitragen. Es handelt sich dabei meist um pixel-große Bereiche. Ihre Anordnung im Differenzbild zeigt deutliche Aliasingartefakte in Form von regelmäßigen Mustern, was auf die Arbeitsweise des Analyse-Passes zurückgeführt werden kann. 

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/difference.png}
  \caption{Unterschiede der Verfeinerung zu zwei Zeitpunken\label{difference}}
\end{figure}

In der 13 Sekunde beginnt die umkreisende Bewegung der Kamera, die zu einem deutlichen Anstieg der Menge der angeforderten Treelets führt. Bei 18.5 Sekunden ist die Umkreisung so weit vorangeschritten, dass wieder Bereiche des Modells dargestellt werden, die im bisherigen Verlauf des Test schon sichtbar waren. Damit sinkt auch die Menge der angeforderten Treelets. Bei 22.5 Sekunden beginnt die Menge der angeforderten Treelets wieder zu steigen. Der Grund für den Anstieg ist, dass die für die Frontansicht des Models benötigten Treelets bereits aus dem Incore-Buffer verdrängt wurden.\\
Drei Sekunden nach Beendigung der Umkreisung war die im Incore-Buffer enthalte Octree-Struktur erneut an die Ansicht angepasst.\\
\\
Der Test zeigt, dass das vorgestellte Out-of-Core-System schnell auf Veränderungen der Ansicht mit Änderungen der Auswahl der Octree-Segmente reagieren kann. Die mit dem System erzielte Bildrate lag im Test meist über 50 Hz. Dabei wurden Out-of-Core-System und Bildgenerierung durch Raycasting sequentiell ausgeführt. Die Auflösung des Bild-Buffers in diesem Test betrug 1024x1024 Pixel.

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/kamera_fahrt.pdf}
  \caption{Reaktionszeit des Systems\label{kamera_fahrt}}
\end{figure}

% /////////////////////////////////////////////////////////////

\newpage
\newpage
\section{Einschränkungen und Verbesserungen}

\subsection{Verwendung von OpenGL Texturen als Buffer}
\subsection{Entkoppelung des Out-of-Core-Systems von der Bilderzeugung}
...
