\chapter{Ergebnisse und Diskussion}



% /////////////////////////////////////////////////////////



\section{Überblick}
Abbildung \ref{lucy_s4_D13_timeseries} gibt einen allgemeinen Eindruck über die Laufzeiten der einzelnen Teilschritte, die in Abschnitt \ref{sec:echtzeitfaehiges_svo_raycasting} (\nameref{sec:echtzeitfaehiges_svo_raycasting}) beschrieben wurden und die Anzahl verarbeiteter Treelets. Die Werte wurden in Abständen von 200 ms abgegriffen.
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/lucy_s4_D13_timeseries.pdf}
  \caption{Systemzeiten und zu verarbeitende Treelets Treelets\label{lucy_s4_D13_timeseries}}
\end{figure}
Im oberen Graphen finden sich die Zeiten für das Erstellen des Analyse-Buffers, das Zurücklesen und dessen Vorsortierung in Sichtinformationen für neue und bereits geladene Treelets. Ausserdem sind die benötigten Zeiten für die Pflege des clientseitigen und serverseitigen Incore-Buffers dargestellt. Im unteren Graphen sind die Menge der von der Analyse des Baumes erzeugten Anfragen nach neuen Treelets, die Menge der daraufhin geänderten Slots und die Anzahl der benötigten Kopieraufrufe dargestellt.\\
Um Eigenschaften und Leistungsfähigkeit des Systems zu analysieren wurden im Zuge dieser Arbeit drei Tests durchgeführt. Der erste Test untersuchte den Einfluss der Treelet-Größe auf das Verhalten des Out-of-Core-Systems. Der zweite Test beschäftigt sich mit der Minimierung der Kopieraufrufe bei der serverseitigen Aktualisierung. Ein dritter Test soll die Reaktionsfähigkeit des Systems während der Benutzung untersuchen.\\
Als Testsystem stand ein aktuelles GNU/Linux-System mit Intel Core i7-2600 (3.4 GHz) und 32 GB Arbeitsspeicher zu Verfügung. Eine Nvidia GForce 580 GTX mit 1.5 GB Ram war über PCI-Express 2 angebunden. 


% /////////////////////////////////////////////////////////


\section{Verwendete Testmodelle}
 
Als Testdaten wurde drei Dreiecksmodelle mit Hilfe des in Kapitel \ref{sec:erzeugung_treelet_struktur} (\textit{\nameref{sec:erzeugung_treelet_struktur}}) beschrieben Systems in Sparse Voxel Octrees überführt. Aus jedem Modell wurden jeweils zwei SVO-Strukturen erstellt. Beide Varianten haben die selbe minimale Tiefe von 13 für alle Blattknoten, unterscheiden sich aber in der Treelet-Größe, die 1 kB und 4 kB beträgt. Tabelle \ref{tab:verwendete_modelle} zeigt die Anzahl der Dreiecke der verwendeten Ausgangsmodelle und Anzahl von Treelets und Voxel der resultierenden Octrees. 
Für alle Octrees wurden Attribut-Buffer mit Farb- und Normalenwerten erstellt die mit 16 Byte/Voxel aufgelöst sind die in den angegebenen zum Speicherbedarf bereits enthalten sind.\\
Das Modell "david face" stellt eine Besonderheit dar. Durch die feste Segmentgröße ist die Darstellung mit 4 kB-großen Treelets unverhältnismässig groß geworden.


\begin{table}[position=h]
\changefont{ptm}{m}{n}
\normalsize
\centering
\begin{tabular}{ l  r  r  c  r r r}
\toprule
\textbf{Name} & \textbf{Dreiecke} & \textbf{Dateigröße} & \textbf{Treelet-Größe} & \textbf{Treelets} & \textbf{Voxel} & \textbf{Dateigröße} \\
\midrule
  david face        & 52.5 Mio & 14.7 GB & 1kb & 743.277 &  95.139.456 & 1.4 GB \\

                    &          &         & 4kb & 484.297 & 247.960.064 & 3.7 GB \\
\midrule
  Lucy              & 28.0 Mio & 757 MB & 1kb & 588.032  & 75.268.096 & 1.2 GB \\
                    &          &        & 4kb & 131.072  & 67.108.864 & 1.0 GB \\
\midrule
  xyzrgb statuette  & 10.0 Mio & 270 MB & 1kb & 781.302 & 100.006.656 & 1.5 GB \\
                    &          &        & 4kb & 246.434 & 126.174.208 & 1.9 GB \\ 
\bottomrule 
\end{tabular}\\
%\vspace{0.2cm}
%\hrule height 1pt width 1.0\hsize
\caption{Verwendete Modelle}\label{tab:verwendete_modelle}
\end{table}

% /////////////////////////////////////////////////////////////

\newpage

\section{Einfluss der Segmentgröße auf das Systemverhalten}\label{sec:test_einfluss_groesse}
\subsection{Versuchsaufbau}
Bei diesem Test soll der Einfluss der Speichergröße der Treelets auf das Laufverhalten des Systems untersucht werden. Dazu wurden für alle sechs Modelle die Werte wie sie in Abbildung \ref{lucy_s4_D13_timeseries} dargestellt sind aufgenommen. Aufnahme Zeit betrug in allen Durchläufen 30 Sekunden. In Intervallen von 200 ms wurde jeweils ein Wert notiert der dem Mittelwert aller in dieser Zeit erfolgten Programmzyklen entspricht.\\
Um das System zu belasten und die permanente die Veränderung des Incore-Buffers anzuregen wurden alle Modelle vor der Kamera platziert und mit $1/3$ Hz um die Hochachse rotiert. Mit der Bewegung sollte gewährleistet werden, dass das System in jedem Durchlauf eine hohe Anzahl von Anfragen nach neuen Treelets erzeugt und verarbeiten muss. Die Geschwindigkeit der Rotation wurde gewählt um einen wahrscheinlichen Anwendungs\-fall zu simulieren, in dem eine hohe Kohärenz zwischen den aufeinander\-folgenden Ansichten erwartet wird. Die Größe des Incore-Buffers wurde auf 256 MB festgelegt und entspricht damit $1/4$ bis $1/14$ der Speichergrößen der gesamten Octreedaten. Um das Laufverhalten über einen längeren Zeitraum zu simmulieren wurde das Model vor der eigentlichen Messung über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet. Dies führt zu einer unsystematischen Anordnung der Treelets im Incore-Buffer. Während der Messung wurde die Bildsynthese deaktiviert, um ausschließlich den Einfluss der Größe der Treelets auf den Ver\-walt\-ungsaufwand untersuchen zu können.



% /////////////////////////////////////////////////////////////



\subsection{Auswertung}
Die in Abbildung \ref{david_lucy_xyzrgb_s1_vs_24_D13} dargestellte Vergleich der Messergebnisse für unterschiedliche Treeletgrößen zeigt für alle drei Modelle ähnliche Tendenzen auf.\\
\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/david_lucy_xyzrgb_s1_vs_24_D13.pdf}
  \caption{Gegenüberstellung unterschiedleichen Treelet-Größen\label{david_lucy_xyzrgb_s1_vs_24_D13}}
\end{figure}
\\
\subsubsection{Erstellung und Übertragung des Analyse-Buffers}
Zunächst kann festgestellt werden, dass die Erstellungszeit für den Analyse-Buffer für zwei der drei Beispiele in beiden Varianten annähernd konstant ist. Der Unterschied beim Modell \textit{david face} kann durch den enormen Unterschied in der Anzahl der Knoten beider Darstellungen erklärt werden der immerhin 260\% beträgt. Trotzdem benötigt die 4Kb Version nur ca. 0.2 ms mehr für das Erstellen des Buffers. Daraus läßt sich schließen dass die Größe der Treelets, für die Gewählten Werte von 1 kB und 4 kB, keinen nenenswerten Einfluss auf das beim Erstellen stattfindende Raycasting besitzt. Der Algorithmus skaliert sehr gut, trotz der Segmentierung.\\
Die nötige Übertragung des Analyse-Buffers in den Hauptspeicher der CPU läuft erwartungsgemäß in konstanter Zeit ab.

\subsubsection{Vorsortierung}
Der Vorsortierungsschritt benötigt bei allen drei Modellen für die Variante mit kleinen Treelets mehr Zeit als für ihre 4 kB Pendants. Der größere zu bewältigende Verwaltungsaufwand bei der Erstellung der Sichtinformation und Anfragen nach neuen Treelets dürfte der Grund für dieses Ergebniss sein. Beispielsweise muss bei der Behandlung eines Elementes des Analysebuffers das einen Knoten getroffen hatte, die Sichtbarkeit des Entsprechenden Treelets bis zu Wurzel-Treelet durchgereicht werden. Falls ein Treelet angehangen werden kann, wird der entsprechende Index mit dem Fehlerwert für diesen Bildpunkt in den Container mit allen Treelet-Anfragen sortiert um sie, ihrem Beitrag zur Bildqualität nach, einpflegen zu können.\\
Da die Unterteilung bei 1 kB großen Treelets feiner ist, ist auch der Weg zum Propagieren der Sichtbarkeitsinformationen länger. Auch ist der Vorgang bei kleinen Treelets wohl kaum Speicher\-kohärent da es wesentlich mehr Blätter und damit mehr Wege von Blättern zum Wurzel-Knoten gibt. Die feinere Unterteilung führt im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) zu einer Größeren Menge von Anfragen nach neuen Treelets.

\subsubsection{Clientseitige Aktualisierung}
Im zweiten und dritten Beispiel (\textit{lucy} und \textit{xyzrgb statuette}) sind die Zeiten für die Pflege des clientseitigen Incore-Buffers (obere Graphen, grün) nahezu identisch obwohl sich die Menge an vorhandenen Treelets der Modelle stark unterscheidet. Die großere Anzahl von Slot-Änderungen (untere Graphen, grau) weißt auf eine Mehrlast für mehr verwaltete Treelets hin. Besonders beim Modell \textit{lucy} mit 1 kB Treelets wird dies deutlich, da es mit Abstand die meisten Treelets der vier Octrees besitzt. Damit kann abgeleitet werden das die clientseitge Aktualisierung mit steigender Treelet-Anzahl gut skaliert. Allerdings lässt sich über alle Modelle eine stärkere Abhängigkeit der Laufzeit von den neu angeforderten Treelets (untere Graphen, lila) erkennen 

\subsubsection{Serverseitige Aktualisierung}
Das kopieren der geänderten Slot-Bereiche auf den Server beansprucht bei fast allen Versuchen einen großen Anteil der Laufzeit. Das Zusammenfassen der Slot-Bereiche funktioniert, wie ein Vergleich der Anzahl der geänderten Slots (unterer Graph, grau) mit der Anzahl der ausgeführten Kopieroperationen (unterer Graph, blau) veranschaulicht. Ob die Zusammenfassung tatsächlich einen Geschwindigkeitsvorteil gegenüber dem einzelnen Kopieren der Slot-Bereiche bring, sollte ein zweiter Test untersuchen der in Abschnitt \ref{sec:test_zusammenfassen_von_slots} (\textit{\nameref{sec:test_zusammenfassen_von_slots}}) dokumentiert ist.

\subsubsection{Anmerkungen zum Modell david face}
Das Modell \textit{david face} stellt eine Besonderheit zwischen den ausgewählten Testmodellen dar. Durch die Segmentierung mit 4 kB großen Treelets sehr viele Knoten entstanden sind die Unterhalb der geforderten Tiefe liegen. Dies passiert beim Aufbau der Octree-Struktur im Build-Manager, wenn die gewünschte Octree-Tiefe mit den bisher erstellten Treelets beinahe erreicht wurde. Auf Voxel-Ebene würde es ausreichen noch einige wenige Unterteilungen vorzunehmen um die benötigte Tiefe zu erreichen. Da aber für jeden Blattknoten des bisher erstellten Octrees neue Treelets von 4 kB Größe erzeugt werden wird die Gesamtstruktur sehr groß. Anders ausgedrückt, will man einen Schnitt in der Tiefe 13 durch einen beliebig tiefen Octree abbilden, gelingt das mit 4 Kb großen Segmenten für dieses Modell nur verhältnismäßig grob. Damit offenbart sich ein bedeutender Nachteil einer festen Segmentgröße. Die mögliche Anzahl von Knoten, deren Tiefe die geforderte minimale Baumtiefe übersteigt, erhöht sich mit jeder zusätzlichen Tiefenstufe, da die Anzahl der Blattknoten größer wird. 


% /////////////////////////////////////////////////////////////


\section{Zusammenfassen von Slots bei der Serverseitige Aktualisierung}\label{sec:test_zusammenfassen_von_slots}

Einen großer Teil der Laufzeit des Out-of-Core-Systems wird vom Aktualisieren des serverseitigen Incore-Buffers beansprucht. Daher hätte eine Optimierung dieses Vorgangs einen großen Einfluss auf die Gesamtleistung des Systems. Es wurde zunächst vermutet das die große Anzahl der Kopieropterationen vom clientseitigen zum serverseitigen Incore-Buffer für den Großteil der benötigten Zeit verantwortlich ist. Mit dem Zusammenfassen der Speicherbereiche mehrerer zu aktualisierenden Slots wurde versucht die Anzahl der Kopieroperationen zu minimieren. Der eingestellte Anteil der Nutzdaten an dem zu kopierenden Speicherbereich wirkt sich dabei entscheident auf die benötigte Laufzeit ab. Ist der Anteil zu hoch festgelegt können nur wenige Bereiche zusammengefasst werden. Ist er dagegen zu hoch wird im Extremfall der Bereich des gesamten Incore-Buffer zu einer Kopieroperation zusammengefasst. Das wäre sehr ungünstig da zum Übertragen einer so großen Datenmenge mehr Zeit benötigt würde als bei der Einzel\-übertragung der Slot-Bereiche. Es muss also eine Einstellung für den Anteil von Nutzdaten geben der die benötigte Zeit für das Kopieren minimiert. Um diese Einstellung für eine gegebene Konfiguration von Incore-Buffer-Größe und Eingabedaten zu finden wurde dieser Test durchgeführt.


\subsection{Versuchsaufbau}
Das Modell \textit{david face} mit 4 KB großen Treelets wurde analog zum ersten Test vor der Kamera bewegt. In zehn Durchläufen wurden die Zeit für die serverseitige Aktualisierung, die Menge der veränderten Slots und die Anzahl der ausgeführten Kopieroperationen über 30 Sekunden aufgezeichnet. Dabei wurde der geforderte Nutzdatenanteil in jedem Durchlauf von $0$ beginnend, um 0.1 erhöht. Um Artefakte in den gemessenen Werten zu verhindern, wurde das Model wieder vor der eigentlichen Messung über 30 Sekunden aus zufällig gewählten Perspektiven verarbeitet.


\subsection{Auswertung}
Abbildung \ref{ratio_0_1} zeigt die Ergebnisse für die gemessene Zeit für das Kopieren, die Anzahl von geänderten Slots und die für die durchgeführten Kopieroperationen. Dabei entspricht ein Anteil von 0 dass kopierte Bereiche keine Nutzdaten enthalten müssen. Ein Anteil von 1.0 verlangt dagegen dass jeder in einem zu kopierten Bereich liegender Slot auch kopiert werden muss. In der Abbildung lässt sich ein Optimum für den Nutzdatenanteiles bei 0.6 erkennen. Mit dieser Einstellung betrug die Zeit für die Übertragung im Durchschnitt bei 2.48 ms. Zum Vergleich lag die Zeit für das einzelne Kopieren der Bereiche im Durchschnitt bei bei 4.23 ms. Der im Graph nicht dargestellte Wert für einen Nutzdatenanteil von Null lag dagegen bei 52.51 ms.\\
Ein Optimum existiert also und kann in der Anwendung auch ausgenutzt werden. Wie sich der Wert jedoch im laufenden System ändert und wie er in Abhängigkeit zu anderen Systemparametern steht konnte im Zuge dieser Arbeit nicht untersucht werden.


\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/ratio_0-1.pdf}
  \caption{Idealwert für Nutzdatenanteil\label{ratio_0_1}}
\end{figure}


% /////////////////////////////////////////////////////////////


\section{Test der Reaktionsfähigkeit des Systems}
In diesem Versuch sollte die Reaktionsfähigkeit des Systems untersucht werden. Dazu wurde die Zeit gemessen die das System benötigt um auf eine Sichtveränderung zu reagieren in dem es den aktuell sichtbaren Teil des Octrees bis zum nötigen beziehungsweise möglichen Grad verfeinert. Die Anzahl der zur Verfeinerung angeforderten Treelets kann dabei als Fehlerwert, für den momentan im Incore-Buffer befindlichen Teil des Octrees gegenüber einer Ansicht auf den gesamten Octree, gesehen werden.


\subsection{Versuchsaufbau}
Für diesen Test wurde die betrachtende Kamera zunächst auf das SVO-Model gerichtet und dann die Verfeinerung des Octrees aktiviert. Nachdem die Verfeinerung für diese Ansicht abgeschlossen war wurde die Kamera in einer schnellen Bewegung auf das Modell zu bewegt um davor wieder zum Stehen zu kommen. Wieder wurde gewartet bis die Verfeinerung der Ansicht abgeschlossen war. Danach wurde das Modell noch einmal in einer schnellen Bewegung umkreist. Wärent dieses Ablaufs wurden Werte für die Kamerageschwindigkeit, die benötigte Zeit für die Bildsynthese und den Gesamtzyklus sowie für die Anzahl der angeforderten Treelets aufgezeichnet.


\subsection{Auswertung}
Für eine korrekte Interpretation der Ergebnisse ist anzumerken, !!!!!!! dass die Sortierung der Anfragen nach ihrem Fehler in der Darstellung wärend der Vorsortierung dafür sorgt, dass zuerst die Treelets eingepflegt werden die den größten Beitrag zur Darstellungs\-qualität liefern (vgl. Abschnitt \ref{sec:streaming_vorsortierung} \textit{\nameref{sec:streaming_vorsortierung}}). Somit finden Verfeinerungen von groben Strukturen zuerst statt während im weiteren Verlauf der Verfeinerung einer Ansicht die Darstellungs\-qualität kaum noch steigt. Das in Abschnitt \ref{sec:streaming_analyse_pass} (\textit{\nameref{sec:streaming_analyse_pass}}) beschriebene Verfahren führt dazu, dass die Verfeinerung nie wirklich beendet ist, da bedingt durch die Unterabtastung beim Füllen des Analyse-Buffers immer wieder Blattknoten getroffen werden die in keinem Vorherigen Analyse-Pass zu sehen waren.
Diese müssen aber sehr klein sein um längere Zeit vom Analyse-Pass unentdeckt zu bleiben. Daher ist auch deren Beitrag zur Bild\-qualität zu vernachlässigen. Abbildung \ref{progressive_refinement} zeigt die Verfeinerung einer Ansicht in fünf auf einander folgenden Schritten. Der Fehler in der Darstellung ist in der unteren Reihe auf einen Farbverlauf von Grün über Gelb nach Rot abgebildet. Die Darstellungen lassen erkennen, dass die Verfeinerung bereits nach wenigen Schritten so weit vorangeschritten ist, dass die weiterhin stattfindende Verfeinerung kaum noch zur wahrgenommenen Bildqualität beiträgt.  

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/progressive_refinement.png}
  \caption{Verfeinerung für eine Ansicht in fünf Schritten\label{progressive_refinement}}
\end{figure}

\newpage
Abbildung\ref{kamera_fahrt} zeigt die Ergebnisse der durchgeführten Messung. Von Zeitpunkt Null an beginnt die Verfeinerung der Octree-Struktur und ist nach etwa 3.5 Sekunden praktisch abgeschlossen. Nach vier Sekunden beginnt die Kamera\-bewegung in Richtung Modell, welche nach weiteren fünf Sekunden beendet ist. In dieser Zeit gibt es einen deutlichen Anstieg der benötigten Zeit für die Bildsynthese, da bedingt durch die steigende Größe des Models im Bildausschnitt beim Raycasting mehr Strahlen den Octree traversieren müssen. Ab etwas der Hälfte der Zeit beginnt die Verfeinerung des weiter voranzuschreiten da Octree-Tiefe der geladenen Treelets nicht mehr für die Darstellung in dieser Entfernung genügt. Vier Sekunden nach der Beendigung der Kamerabewegung ist die Verfeinerung

\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/kamera_fahrt.pdf}
  \caption{Reaktionszeit des Systems\label{kamera_fahrt}}
\end{figure}



\begin{figure}[position=h]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/difference.png}
  \caption{Unterschiede der Verfeinerung zu zwei Zeitpunken\label{difference}}
\end{figure}

% /////////////////////////////////////////////////////////////

\newpage
\newpage
\section{Einschränkungen und Verbesserungen}

\subsection{Verwendung von OpenGL Texturen als Buffer}
\subsection{Entkoppelung des Out-of-Core-Systems von der Bilderzeugung}
...
