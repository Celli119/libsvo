\chapter{Einleitung}
\section{Motivation}
Seit ihrer Vorstellung in den späten 70er Jahren (!!! REFERENCE) ist die Bildsynthese durch Rasterisierung von parametrisierten Dreiecken der Quasi-Standard für Echtzeitcomputergrafik. Diese Entwicklung wurde nicht zuletzt durch die Einführung von dezidierter Hardware und offenen Standards, wie OpenGL möglich. Der Vorteil von Dreiecken als Geometrieprimitiv ist, dass sich mit ihnen sehr effizient planare Flächen darstellen lassen, wobei die Größe der abgebildeten Flächen keinen Einfluss auf den Speicherbedarf der Repräsentation hat. In modernen Anwendungen, wie Spielen oder bei der Darstellung von hochauflösenden 3d-Scanns ist dieser Vorteil jedoch immer weniger relevant, da der überwiegende Teil des benötigten Speichers durch Texturen belegt wird, welche die Flächen mit Details versehen. Dabei ist die Parametrisierung von komplex geformten Dreiecksnetzen nicht trivial und muss deshalb meist händisch bewerkstelligt werden.\\
Bei der Rasterisierung von detaillierten Dreiecksnetzen mit hoch aufgelösten Texturen kommt es schnell zu Aliasing\-artefakten. Um diese zu reduzieren, werden von Dreiecksnetz und Texturen niedriger aufgelöste, statische Versionen erzeugt, zwischen denen bei der Darstellung je nach Betrachtungsabstand gewechselt wird, was zu störenden \textit{Popping}-Artifakten führt. Dabei kann nur im seltensten Fall ein ideales Verhältnis zwischen Geometrie- und gegebener Bildauflösung gewährleistet werden. Das Erstellen von \textit{Level-of-Detail}-Stufen (\textit{LOD}) aus einem hochauflösenden Dreiecksnetz ist nur mit hohen Rechen- oder Speicheraufwand dynamisch zu bewerkstelligen. Außerdem muss das LOD-Problem für Geometrie und Texturdaten während der Erstellung und der Darstellung separat gelöst werden. Ein Nachteil des Rasterisierungsansatzes ist das Fehlen von globalen Informationen während der Fragmentgenerierung. Jedes Primitiv wird für sich behandelt ohne das globale Informationen zur Optimierung (\textit{Culling}) oder Beleuchtung (\textit{Global Illumination}) zur Verfügung stehen.\\ \\
Die Generalisierung der Renderpipelines und die Einführung von GPGPU-Hochsprachen wie OpenCL machen es möglich die Frage nach geeignetem Geometrieprimitiv und Bildsyntheseverfahren neu zu stellen. Sparse Voxel Octree als Datenstruktur in Kombination mit \textit{Raycasting} als Algorithmus zur Bildsynthese bieten viele positive Eigenschaften. So vereinen Sparse Voxel Octrees Geometrie und Texturdaten in einer einzigen hierarchischen Struktur. Durch Raycasting auf dieser Struktur kann das Problem der Wahl der Detailgrade von Geometrie und Textur gemeinsam pro Bildpunkt gelöst werden. Gleichzeitig wirkt der Octree als Beschleunigungsstruktur, so dass während des Traversierens nur die Teile der Struktur durchlaufen werden, die zur Bildsynthese beitragen. Eine Parametrisierung ist nicht notwendig, da jedes Voxel seine eigenen, für seine Größe optimal aufgelösten, Attributinformationen speichert.\\
...
\textbf{Probleme:} keine Tools bzw. generalisierte Pipeline zur Erstellung von SVO-Content vorhanden\\
\textbf{Probleme:} Trotz Sparse enorme Datenmenge


\section{Zielstellung}

\textbf{Zeilstellung 1:} Entwicklung eines Templates zur Generierung von SVO aus unterschiedlichen Datenvorlagen (Dreiecke, Pointclouds, Heightmaps, volumen).\\
\\
\textbf{Zeilstellung 2:} Entwicklung eines Out-Of-Core Ansatzes basierend auf Segmentierung der SVO Daten und adaptives refinement
  
  